{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()  # 加载 .env 文件中的环境变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.llms.langchain import LangChainLLM\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from langchain_openai import ChatOpenAI\n",
    "from llama_index.embeddings.dashscope import (\n",
    "    DashScopeEmbedding,\n",
    "    DashScopeTextEmbeddingModels,\n",
    "    DashScopeTextEmbeddingType,\n",
    ")\n",
    "\n",
    "embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\")\n",
    "embed_model_ali = DashScopeEmbedding(model_name=DashScopeTextEmbeddingModels.TEXT_EMBEDDING_V3,text_type=DashScopeTextEmbeddingType.TEXT_TYPE_DOCUMENT)\n",
    "\n",
    "llm = OpenAI(model=\"gpt-4o-mini\")\n",
    "llm_doubao = LangChainLLM(llm=ChatOpenAI(model=\"doubao-1.5-vision-32k\"))\n",
    "\n",
    "Settings.embed_model = embed_model_ali\n",
    "Settings.llm = llm_doubao\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_cloud_services import LlamaParse\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "#还没有生成md_json_list.pkl文件\n",
    "if not os.path.exists(\"md_json_list.pkl\"):\n",
    "    parser = LlamaParse(\n",
    "        result_type=\"markdown\",\n",
    "        use_vendor_multimodal_model=True,\n",
    "        vendor_multimodal_model_name=\"gemini-2.0-flash-001\",\n",
    "        language=\"ch_sim\"\n",
    "    )\n",
    "    md_json_objs = parser.get_json_result(\"data/中文大模型基准测评2025年3月报告.pdf\")\n",
    "    md_json_list = md_json_objs[0][\"pages\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把解析结果取下来，只需要运行一次，要等待上一步parse完成，找到这里的job_id\n",
    "\n",
    "import pickle\n",
    "if not os.path.exists(\"md_json_list.pkl\"):\n",
    "    md_result =await parser._get_job_result('7e1be6ef-af58-462f-a339-1a3eba62fd0a',result_type='json')\n",
    "    md_result[\"job_id\"] = \"7e1be6ef-af58-462f-a339-1a3eba62fd0a\"\n",
    "\n",
    "    image_dicts = parser.get_images([md_result], download_path=\"data_images\")\n",
    "    md_json_list = md_result[\"pages\"]\n",
    "\n",
    "    #存储到本地，方便后续使用\n",
    "    pickle.dump(md_json_list, open(\"md_json_list.pkl\", \"wb\"))\n",
    "    pickle.dump(image_dicts, open(\"image_dicts.pkl\", \"wb\"))\n",
    "else:\n",
    "    md_json_list = pickle.load(open(\"md_json_list.pkl\", \"rb\"))\n",
    "    image_dicts = pickle.load(open(\"image_dicts.pkl\", \"rb\"))\n",
    "    print(md_json_list[13])\n",
    "    print(image_dicts[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from llama_index.core.schema import TextNode\n",
    "from typing import Optional\n",
    "# get pages loaded through llamaparse\n",
    "import re\n",
    "\n",
    "def get_page_number(file_name):\n",
    "    match = re.search(r\"-page_(\\d+)\\.jpg$\", str(file_name))\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    return 0\n",
    "\n",
    "def _get_sorted_image_files(image_dir):\n",
    "    \"\"\"Get image files sorted by page.\"\"\"\n",
    "    raw_files = [f for f in list(Path(image_dir).iterdir()) if f.is_file() and f.suffix == '.jpg']\n",
    "    sorted_files = sorted(raw_files, key=get_page_number)\n",
    "    return sorted_files\n",
    "\n",
    "print(_get_sorted_image_files(\"./data_images\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#控制参数\n",
    "\n",
    "#是否启用文本摘要\n",
    "ENABLE_TEXT_SUMMARY = True\n",
    "\n",
    "#是否启用问题抽取\n",
    "ENABLE_EXTRACTED_QUESTIONS = True\n",
    "\n",
    "#是否拆分成小文本节点\n",
    "ENABLE_SMALL_TEXT_NODES = False\n",
    "\n",
    "#是否启用关键词索引\n",
    "ENABLE_KEYWORDS_INDEX = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_prompt = \"\"\"\n",
    "这是我们希望在整个文档中查找的块：\n",
    "<chunk>\n",
    "{CHUNK_CONTENT}\n",
    "</chunk>\n",
    "请给出一个简短的摘要，以方便在整个文档中定位这个块，以提高块的检索效果。只回答简短的摘要内容，不要回答其他内容。\n",
    "\"\"\"\n",
    "def generate_summary(json_dicts, llm):\n",
    "    for obj in json_dicts:\n",
    "        print(f'Start generating summary for page {obj[\"page\"]}')\n",
    "        md_text = obj[\"md\"]\n",
    "        prompt = summary_prompt.format(CHUNK_CONTENT=md_text)\n",
    "        summary = llm.complete(prompt)\n",
    "        print(summary)\n",
    "        obj[\"summary\"] = summary\n",
    "    return json_dicts\n",
    "\n",
    "# 生成摘要信息\n",
    "if ENABLE_TEXT_SUMMARY:\n",
    "\n",
    "    import pickle,os\n",
    "    if os.path.exists(\"json_dicts_with_summary.pkl\"):\n",
    "        json_dicts_with_summary = pickle.load(open(\"json_dicts_with_summary.pkl\", \"rb\"))\n",
    "    else:\n",
    "        json_dicts_with_summary = generate_summary(md_json_list, llm_doubao)\n",
    "        pickle.dump(json_dicts_with_summary, open(\"json_dicts_with_summary.pkl\", \"wb\"))\n",
    "    \n",
    "    for obj in json_dicts_with_summary:\n",
    "        print(obj[\"summary\"])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "\n",
    "def get_text_nodes(image_dir=None, json_dicts=None):\n",
    "    \n",
    "    nodes = []\n",
    "\n",
    "    image_files = _get_sorted_image_files(image_dir) if image_dir is not None else None\n",
    "    \n",
    "    for idx, obj in enumerate(json_dicts):\n",
    "\n",
    "        chunk_metadata = {}\n",
    "        chunk_metadata[\"page_num\"] = idx + 1\n",
    "        chunk_metadata[\"image_path\"] = str(image_files[idx])\n",
    "\n",
    "        if \"summary\" in obj:\n",
    "            chunk_metadata[\"text_summary\"] = str(obj[\"summary\"])\n",
    "\n",
    "        node = TextNode(\n",
    "            text = obj[\"md\"],\n",
    "            metadata=chunk_metadata,\n",
    "        )\n",
    "        nodes.append(node)\n",
    "\n",
    "    return nodes\n",
    "\n",
    "if ENABLE_TEXT_SUMMARY:\n",
    "    text_nodes = get_text_nodes(image_dir=\"data_images\", json_dicts=json_dicts_with_summary)\n",
    "else:\n",
    "    text_nodes = get_text_nodes(image_dir=\"data_images\", json_dicts=md_json_list)\n",
    "\n",
    "print(text_nodes[1].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.extractors import QuestionsAnsweredExtractor\n",
    "DEFAULT_QUESTION_GEN_TMPL = \"\"\"\\\n",
    "以下是上下文信息:\n",
    "{context_str}\n",
    "根据上下文信息，生成 {num_questions} 个问题，这些问题的具体答案不太可能在其他地方找到。\n",
    "注意问题必须是上下文能够回答的问题，不要问关于上下文之外的问题。\n",
    "直接输出问题，不要多余说明。\n",
    "\"\"\"\n",
    "\n",
    "if ENABLE_EXTRACTED_QUESTIONS:\n",
    "    if os.path.exists(\"extract_questions.pkl\"):\n",
    "        extract_questions = pickle.load(open(\"extract_questions.pkl\", \"rb\"))\n",
    "    else:\n",
    "        questions_extractor = QuestionsAnsweredExtractor(llm=llm_doubao,prompt_template=DEFAULT_QUESTION_GEN_TMPL,metadata_mode='none',questions=5)\n",
    "        extract_questions = questions_extractor.extract(text_nodes)\n",
    "        pickle.dump(extract_questions, open(\"extract_questions.pkl\", \"wb\"))\n",
    "        \n",
    "    for idx, node in enumerate(text_nodes):\n",
    "        node.metadata.update(extract_questions[idx])\n",
    "\n",
    "    for node in text_nodes:\n",
    "        print(node.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in text_nodes:\n",
    "    node.excluded_embed_metadata_keys= [\"page_num\", \"image_path\"]\n",
    "    node.excluded_llm_metadata_keys = [\"page_num\", \"image_path\",\"text_summary\",\"questions_this_excerpt_can_answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import MarkdownNodeParser,SemanticSplitterNodeParser\n",
    "\n",
    "if ENABLE_SMALL_TEXT_NODES:\n",
    "    markdown_parser = MarkdownNodeParser(show_progress=True)\n",
    "    small_text_nodes = markdown_parser.get_nodes_from_documents(text_nodes)\n",
    "\n",
    "    print(len(small_text_nodes))\n",
    "    for node in small_text_nodes:\n",
    "        print(node.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import chromadb\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core import (\n",
    "    StorageContext,\n",
    "    VectorStoreIndex,\n",
    "    load_index_from_storage,\n",
    "    KeywordTableIndex\n",
    ")\n",
    "\n",
    "vector_retriever = None\n",
    "kw_retriever = None\n",
    "\n",
    "# Define paths\n",
    "small_top_k = 20\n",
    "top_k = 3\n",
    "\n",
    "def create_vector_retriever(nodes_to_index):\n",
    "\n",
    "    STORAGE_DIR_VECTOR = \"./storage_nodes/vector\"\n",
    "\n",
    "    chroma_client = chromadb.HttpClient(host=\"localhost\", port=8000)\n",
    "    if not os.path.exists(STORAGE_DIR_VECTOR):\n",
    "        chroma_client.delete_collection(\"rag_collection\")\n",
    "    collection = chroma_client.get_or_create_collection(\"rag_collection\")\n",
    "    vector_store = ChromaVectorStore(chroma_collection=collection)\n",
    "\n",
    "    if not os.path.exists(STORAGE_DIR_VECTOR):\n",
    "        print(f'Creating vector index【{len(nodes_to_index)} nodes】...\\n')\n",
    "        storage_context =  StorageContext.from_defaults(vector_store=vector_store)\n",
    "        index = VectorStoreIndex(nodes_to_index,storage_context=storage_context,show_progress=True,insert_batch_size=5)\n",
    "        index.storage_context.persist(persist_dir=STORAGE_DIR_VECTOR)\n",
    "    else:\n",
    "        print(f'Loading vector index【{len(nodes_to_index)} nodes】...\\n')\n",
    "        storage_context = StorageContext.from_defaults(persist_dir=STORAGE_DIR_VECTOR,vector_store=vector_store)\n",
    "        index = load_index_from_storage(storage_context=storage_context)\n",
    "\n",
    "    #向量检索\n",
    "    vector_retriever = index.as_retriever(similarity_top_k=small_top_k if ENABLE_SMALL_TEXT_NODES else top_k)\n",
    "    return vector_retriever\n",
    "\n",
    "def create_keyword_retriever(nodes_to_index):\n",
    "\n",
    "    STORAGE_DIR_KEYWORD = \"./storage_nodes/keyword\"\n",
    "\n",
    "    if not os.path.exists(STORAGE_DIR_KEYWORD):\n",
    "        print(f'Creating keyeword index【{len(nodes_to_index)} nodes】...\\n')\n",
    "\n",
    "        #构造关键词表索引\n",
    "        kw_index = KeywordTableIndex(nodes_to_index,show_progress=True)\n",
    "        kw_index.storage_context.persist(persist_dir=STORAGE_DIR_KEYWORD)\n",
    "    else:\n",
    "        print(f'Loading keyeword index【{len(nodes_to_index)} nodes】...\\n')\n",
    "        storage_context =  StorageContext.from_defaults(persist_dir=STORAGE_DIR_KEYWORD)\n",
    "        kw_index = load_index_from_storage(storage_context= storage_context)\n",
    "\n",
    "    #返回关键词检索器\n",
    "    kw_retriever = kw_index.as_retriever(num_chunks_per_query=small_top_k if ENABLE_SMALL_TEXT_NODES else top_k)\n",
    "    return kw_retriever\n",
    "\n",
    "vector_retriever = create_vector_retriever(small_text_nodes if ENABLE_SMALL_TEXT_NODES else text_nodes)\n",
    "\n",
    "if ENABLE_KEYWORDS_INDEX:\n",
    "    kw_retriever = create_keyword_retriever(small_text_nodes if ENABLE_SMALL_TEXT_NODES else text_nodes)\n",
    "else:\n",
    "    kw_retriever = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from llama_index.core.retrievers import QueryFusionRetriever\n",
    "\n",
    "if ENABLE_KEYWORDS_INDEX:\n",
    "    fusion_retriever = QueryFusionRetriever(\n",
    "        [vector_retriever, kw_retriever],\n",
    "        similarity_top_k=small_top_k if ENABLE_SMALL_TEXT_NODES else top_k,\n",
    "        num_queries=1,  # set this to 1 to disable query generation\n",
    "        mode=\"reciprocal_rerank\",\n",
    "        use_async=True,\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "else:\n",
    "    fusion_retriever = vector_retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#单个问题检索测试\n",
    "import pandas as pd\n",
    "from llama_index.core.schema import ImageNode, NodeWithScore, MetadataMode\n",
    "from llama_index.core.prompts import PromptTemplate\n",
    "\n",
    "# 获取所有相关的page_num\n",
    "def get_parent_nodes(nodes):\n",
    "    related_page_nums = set(node.node.metadata[\"page_num\"] for node in nodes)\n",
    "\n",
    "    parent_nodes = []\n",
    "    for node in text_nodes:\n",
    "        if node.metadata[\"page_num\"] in related_page_nums:\n",
    "            parent_node = NodeWithScore(node=node, score=0)\n",
    "            parent_nodes.append(parent_node)\n",
    "    \n",
    "    for parent_node in parent_nodes:\n",
    "        print(parent_node.score)\n",
    "        parent_node_score = max(node.score for node in nodes if node.node.metadata[\"page_num\"] == parent_node.node.metadata[\"page_num\"])\n",
    "        parent_node.score = parent_node_score\n",
    "\n",
    "    parent_nodes.sort(key=lambda x: x.score, reverse=True)\n",
    "    \n",
    "    return parent_nodes[0:top_k]\n",
    "\n",
    "def recursive_retrieve(query):\n",
    "\n",
    "    nodes = fusion_retriever.retrieve(query)\n",
    "\n",
    "    #for node in nodes:\n",
    "    #    print(f'score: {node.score},metadata: {node.node.metadata}')\n",
    "\n",
    "    if ENABLE_SMALL_TEXT_NODES:\n",
    "        parent_nodes = get_parent_nodes(nodes)\n",
    "        print(f\"{len(parent_nodes)} parent nodes retrieved\")\n",
    "\n",
    "        for node in parent_nodes:\n",
    "            print(f'score: {node.score},metadata: {node.node.metadata}')\n",
    "\n",
    "        return parent_nodes\n",
    "    else:\n",
    "        return nodes\n",
    "\n",
    "recursive_retrieve('SuperCLUE通用基准数据集哪几个维度构成？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#评测功能，如果需要评测检索的准确性，请准备eva_cases.xlsx文件,一个问题，一个对应的页码\n",
    "# Load the eval_cases.xlsx file\n",
    "eval_cases = pd.read_excel(\"./data/eva_cases.xlsx\")\n",
    "\n",
    "def score_retrieval(eval_cases):\n",
    "\n",
    "    total_score = 0\n",
    "    for _, row in eval_cases.iterrows():\n",
    "\n",
    "        score = 0\n",
    "        max_score = top_k\n",
    "\n",
    "        question = row[\"question\"]\n",
    "        true_page = row[\"page\"]\n",
    "\n",
    "        # Retrieve nodes for the question\n",
    "        nodes = recursive_retrieve(question)\n",
    "\n",
    "        # Check the retrieved nodes and calculate the score\n",
    "        for rank, node in enumerate(nodes):\n",
    "            retrieved_page = node.node.metadata[\"page_num\"]\n",
    "            if retrieved_page == true_page:\n",
    "                score += max_score - rank\n",
    "                break\n",
    "\n",
    "        total_score += score\n",
    "        print(f\"Question: {question},true_page: {true_page}, score: {score}\")\n",
    "\n",
    "    print('\\nAverage score:', (total_score / len(eval_cases))*20)    \n",
    "\n",
    "    return total_score\n",
    "\n",
    "# Calculate the score\n",
    "#total_score = score_retrieval(eval_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.query_engine import CustomQueryEngine, SimpleMultiModalQueryEngine\n",
    "from llama_index.core.retrievers import BaseRetriever\n",
    "from llama_index.multi_modal_llms.openai import OpenAIMultiModal\n",
    "from llama_index.core.schema import ImageNode, NodeWithScore, MetadataMode\n",
    "from llama_index.core.prompts import PromptTemplate\n",
    "from llama_index.core.base.response.schema import Response\n",
    "from typing import Optional\n",
    "from llama_index.multi_modal_llms.dashscope import DashScopeMultiModal\n",
    "from llama_index.core.multi_modal_llms import MultiModalLLM\n",
    "import os\n",
    "import base64\n",
    "from doubao import DoubaoVisionLLM\n",
    "\n",
    "lvm = DoubaoVisionLLM(model_name='ep-20250205153642-hzqpj')\n",
    "\n",
    "QA_PROMPT_TMPL = \"\"\"\\\n",
    "以下是幻灯片中解析的Markdown文本和图片信息。Markdown文本已经尝试将相关图表转换为表格。\n",
    "优先使用图片信息来回答问题。在无法理解图像时才使用Markdown文本信息。\n",
    "\n",
    "---------------------\n",
    "{context_str}\n",
    "---------------------\n",
    "\n",
    "-- 根据上下文信息并且不依赖先验知识, 回答查询。\n",
    "-- 解释你是从解析的markdown、还是图片中得到答案的, 如果有差异, 请说明最终答案的理由。\n",
    "-- 尽可能详细的回答问题。\n",
    "-- 给出你重点参考的图片路径。\n",
    "\n",
    "输出格式：{{\"response\": #你的Markdown格式的回答#, \"image_path\": [#与答案最相关的图片路径#]}}\n",
    "\n",
    "查询: {query_str}\n",
    "答案: \"\"\"\n",
    "\n",
    "QA_PROMPT = PromptTemplate(QA_PROMPT_TMPL)\n",
    "\n",
    "class MultimodalQueryEngine(CustomQueryEngine):\n",
    "\n",
    "    qa_prompt: PromptTemplate\n",
    "    multi_modal_llm: MultiModalLLM | DoubaoVisionLLM\n",
    "\n",
    "    def __init__(self, qa_prompt: Optional[PromptTemplate] = None, **kwargs) -> None:\n",
    "        \"\"\"Initialize.\"\"\"\n",
    "        super().__init__(qa_prompt=qa_prompt or QA_PROMPT, **kwargs)\n",
    "\n",
    "\n",
    "    def image_to_base64(self,image_path):\n",
    "        with open(image_path, \"rb\") as image_file:\n",
    "            return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "        \n",
    "    def custom_query(self, query_str: str):\n",
    "        \n",
    "        nodes = recursive_retrieve(query_str)\n",
    "\n",
    "        # create ImageNode items from text nodes\n",
    "        image_nodes = [\n",
    "            NodeWithScore(node=ImageNode(image_path=n.metadata[\"image_path\"]))\n",
    "            for n in nodes\n",
    "        ]\n",
    "        \n",
    "        # create context string from text nodes, dump into the prompt\n",
    "        context_str = \"\\n\\n\".join(\n",
    "            [r.get_content(metadata_mode=MetadataMode.LLM) + f'\\n以上来自图片：{r.metadata['image_path']}' for r in nodes]\n",
    "        )\n",
    "        fmt_prompt = self.qa_prompt.format(context_str=context_str, query_str=query_str)\n",
    "\n",
    "        response = self.multi_modal_llm.generate_response(\n",
    "            prompt=fmt_prompt,\n",
    "            image_paths = [image_node.node.image_path for image_node in image_nodes]\n",
    "        )\n",
    "\n",
    "        return Response(\n",
    "            response=str(response),\n",
    "            source_nodes=nodes,\n",
    "            metadata={\"text_nodes\": text_nodes, \"image_nodes\": image_nodes},\n",
    "        )\n",
    "\n",
    "        return response\n",
    "    \n",
    "multi_query_engine = MultimodalQueryEngine(\n",
    "    multi_modal_llm=lvm\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = multi_query_engine.query(\"3月份中文大模型评测，通用能力水平最高的模型前五名是谁？\")\n",
    "\n",
    "import json\n",
    "from IPython.display import Markdown\n",
    "\n",
    "print(\"\\n*****************************************************************RESPONSE*****************************************************************************************\\n\")\n",
    "response_json = json.loads(response.response)\n",
    "answer = response_json.get(\"response\", \"\")\n",
    "image_paths = response_json.get(\"image_path\", [])\n",
    "\n",
    "# Format the answer and image paths in markdown\n",
    "markdown_output = f\"### Answer:\\n\\n{answer}\\n\\n### Images:\\n\"\n",
    "for image_path in image_paths:\n",
    "    markdown_output += f\"![Image]({image_path})\\n\"\n",
    "    \n",
    "display(Markdown(markdown_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from markitdown import MarkItDown\n",
    "\n",
    "md = MarkItDown(enable_plugins=False) # Set to True to enable plugins\n",
    "result = md.convert(\"data/中文大模型基准测评2024年度报告_simple.pdf\")\n",
    "print(result.text_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from markitdown import MarkItDown\n",
    "from doubao import DoubaoVisionLLM\n",
    "\n",
    "llm_prompt = '''' \n",
    "用中文提取图片中的详细信息，并使用Markdown格式化输出。\n",
    "-- 对于其中的文字，使用OCR识别，并尽量保持原格式或类似格式输出。\n",
    "-- 对于其中的表格与统计图表信息，选择表格结合文字的方式进行描述。\n",
    "-- 对于其他有意义的图像部分，请使用文字描述。 \n",
    "-- 合理排版，使得输出内容清晰易懂\n",
    "''' \n",
    "\n",
    "lvm = DoubaoVisionLLM()\n",
    "\n",
    "result = lvm.generate_response(prompt=llm_prompt, image_paths=[\"data/report_test.png\"])\n",
    "display(Markdown(result))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
